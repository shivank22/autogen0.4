{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncGenerator, List, Sequence, Tuple\n",
    "\n",
    "from autogen_agentchat.agents import BaseChatAgent, AssistantAgent\n",
    "from autogen_agentchat.base import Response\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage, TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "from autogen_agentchat.agents import BaseChatAgent\n",
    "from autogen_agentchat.base import Response\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.messages import ChatMessage\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Agents\n",
    "You may have agents with behaviors that do not fall into a preset. In such cases, you can build custom agents.\n",
    "\n",
    "All agents in AgentChat inherit from BaseChatAgent class and implement the following abstract methods and attributes:\n",
    "\n",
    "on_messages(): The abstract method that defines the behavior of the agent in response to messages. This method is called when the agent is asked to provide a response in run(). It returns a Response object.\n",
    "\n",
    "on_reset(): The abstract method that resets the agent to its initial state. This method is called when the agent is asked to reset itself.\n",
    "\n",
    "produced_message_types: The list of possible ChatMessage message types the agent can produce in its response.\n",
    "\n",
    "Optionally, you can implement the the on_messages_stream() method to stream messages as they are generated by the agent. If this method is not implemented, the agent uses the default implementation of on_messages_stream() that calls the on_messages() method and yields all messages in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAgent(BaseChatAgent):\n",
    "    async def on_messages(self, messages: Sequence[ChatMessage], cancellation_token: CancellationToken) -> Response:\n",
    "        return Response(chat_message=TextMessage(content=\"Custom reply\", source=self.name))\n",
    "\n",
    "    async def on_reset(self, cancellation_token: CancellationToken) -> None:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def produced_message_types(self) -> Sequence[type[ChatMessage]]:\n",
    "        return (TextMessage,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...\n",
      "2...\n",
      "1...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CountDownAgent(BaseChatAgent):\n",
    "    def __init__(self, name: str, count: int = 3):\n",
    "        super().__init__(name, \"A simple agent that counts down.\")\n",
    "        self._count = count\n",
    "\n",
    "    @property\n",
    "    def produced_message_types(self) -> Sequence[type[ChatMessage]]:\n",
    "        return (TextMessage,)\n",
    "\n",
    "    async def on_messages(self, messages: Sequence[ChatMessage], cancellation_token: CancellationToken) -> Response:\n",
    "        # Calls the on_messages_stream.\n",
    "        response: Response | None = None\n",
    "        async for message in self.on_messages_stream(messages, cancellation_token):\n",
    "            if isinstance(message, Response):\n",
    "                response = message\n",
    "        assert response is not None\n",
    "        return response\n",
    "\n",
    "    async def on_messages_stream(\n",
    "        self, messages: Sequence[ChatMessage], cancellation_token: CancellationToken\n",
    "    ) -> AsyncGenerator[AgentEvent | ChatMessage | Response, None]:\n",
    "        inner_messages: List[AgentEvent | ChatMessage] = []\n",
    "        for i in range(self._count, 0, -1):\n",
    "            msg = TextMessage(content=f\"{i}...\", source=self.name)\n",
    "            inner_messages.append(msg)\n",
    "            yield msg\n",
    "        # The response is returned at the end of the stream.\n",
    "        # It contains the final message and all the inner messages.\n",
    "        yield Response(chat_message=TextMessage(content=\"Done!\", source=self.name), inner_messages=inner_messages)\n",
    "\n",
    "    async def on_reset(self, cancellation_token: CancellationToken) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "async def run_countdown_agent() -> None:\n",
    "    # Create a countdown agent.\n",
    "    countdown_agent = CountDownAgent(\"countdown\")\n",
    "\n",
    "    # Run the agent with a given task and stream the response.\n",
    "    async for message in countdown_agent.on_messages_stream([], CancellationToken()):\n",
    "        if isinstance(message, Response):\n",
    "            print(message.chat_message.content)\n",
    "        else:\n",
    "            print(message.content)\n",
    "\n",
    "\n",
    "# Use asyncio.run(run_countdown_agent()) when running in a script.\n",
    "await run_countdown_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticAgent(BaseChatAgent):\n",
    "    def __init__(self,name:str,description: str, operator_func: Callable[[int],[int]]) -> None:\n",
    "        super().__init__(name,description=description)\n",
    "        self._operator_func = operator_func\n",
    "        self._message_history: List[ChatMessage] = []\n",
    "    \n",
    "    @property\n",
    "    def produced_message_types(self) -> Sequence[type[ChatMessage]]:\n",
    "        return (TextMessage,)\n",
    "    \n",
    "    async def on_messages(self,messages: Sequence[ChatMessage],cancellation_token: CancellationToken) -> Response:\n",
    "        self._message_history.extend(messages)\n",
    "\n",
    "        assert isinstance(self._message_history[-1],TextMessage)\n",
    "        number=int(self._message_history[-1].content)   \n",
    "        result = self._operator_func(number)\n",
    "\n",
    "        response_message = TextMessage(content=str(result),source=self.name)\n",
    "\n",
    "        self._message_history.append(response_message)\n",
    "\n",
    "        return Response(chat_message=response_message)\n",
    "    \n",
    "    async def on_reset(self,cancellation_token: CancellationToken) -> None:\n",
    "        self._message_history = []\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Apply the operations to turn the given number into 25.\n",
      "---------- user ----------\n",
      "10\n",
      "---------- multiply_agent ----------\n",
      "20\n",
      "---------- add_agent ----------\n",
      "22\n",
      "---------- add_agent ----------\n",
      "24\n",
      "---------- add_agent ----------\n",
      "26\n",
      "---------- subtract_agent ----------\n",
      "25\n",
      "---------- identity_agent ----------\n",
      "25\n",
      "---------- identity_agent ----------\n",
      "25\n",
      "---------- identity_agent ----------\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "async def run_number_agents() -> None:\n",
    "    # Create agents for number operations.\n",
    "    add_agent = ArithmeticAgent(\"add_agent\", \"Adds 2 to the number.\", lambda x: x + 2)\n",
    "    multiply_agent = ArithmeticAgent(\"multiply_agent\", \"Multiplies the number by 2.\", lambda x: x * 2)\n",
    "    subtract_agent = ArithmeticAgent(\"subtract_agent\", \"Subtracts 1 from the number.\", lambda x: x - 1)\n",
    "    divide_agent = ArithmeticAgent(\"divide_agent\", \"Divides the number by 2 and rounds down.\", lambda x: x // 2)\n",
    "    identity_agent = ArithmeticAgent(\"identity_agent\", \"Returns the number as is.\", lambda x: x)\n",
    "\n",
    "    # The termination condition is to stop after 10 messages.\n",
    "    termination_condition = MaxMessageTermination(10)\n",
    "\n",
    "    # Create a selector group chat.\n",
    "    selector_group_chat = SelectorGroupChat(\n",
    "        [add_agent, multiply_agent, subtract_agent, divide_agent, identity_agent],\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        termination_condition=termination_condition,\n",
    "        allow_repeated_speaker=True,  # Allow the same agent to speak multiple times, necessary for this task.\n",
    "        selector_prompt=(\n",
    "            \"Available roles:\\n{roles}\\nTheir job descriptions:\\n{participants}\\n\"\n",
    "            \"Current conversation history:\\n{history}\\n\"\n",
    "            \"Please select the most appropriate role for the next message, and only return the role name.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Run the selector group chat with a given task and stream the response.\n",
    "    task: List[ChatMessage] = [\n",
    "        TextMessage(content=\"Apply the operations to turn the given number into 25.\", source=\"user\"),\n",
    "        TextMessage(content=\"10\", source=\"user\"),\n",
    "    ]\n",
    "    stream = selector_group_chat.run_stream(task=task)\n",
    "    await Console(stream)\n",
    "\n",
    "\n",
    "# Use asyncio.run(run_number_agents()) when running in a script.\n",
    "await run_number_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "I am happy.\n",
      "---------- assistant ----------\n",
      "{\"thoughts\":\"The user expressed a positive emotion by stating they are happy, indicating a joyful or content state.\",\"response\":\"happy\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='I am happy.', type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=89, completion_tokens=28), content='{\"thoughts\":\"The user expressed a positive emotion by stating they are happy, indicating a joyful or content state.\",\"response\":\"happy\"}', type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Custom Response Type\n",
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# The response format for the agent as a Pydantic base model.\n",
    "class AgentResponse(BaseModel):\n",
    "    thoughts: str\n",
    "    response: Literal[\"happy\", \"sad\", \"neutral\"]\n",
    "\n",
    "\n",
    "# Create an agent that uses the OpenAI GPT-4o model with the custom response format.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=AgentResponse,  # type: ignore\n",
    ")\n",
    "agent = AssistantAgent(\n",
    "    \"assistant\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Categorize the input as happy, sad, or neutral following the JSON format.\",\n",
    ")\n",
    "\n",
    "await Console(agent.run_stream(task=\"I am happy.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
