{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://microsoft.github.io/autogen/dev/reference/python/autogen_ext.tools.graphrag.html\n",
    "https://microsoft.github.io/graphrag/get_started/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %pip install python-dotenv autogen_ext autogen_agentchat\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m----> 4\u001b[0m \u001b[43mload_dotenv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautogen_ext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIChatCompletionClient\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen0.4/lib/python3.12/site-packages/dotenv/main.py:346\u001b[0m, in \u001b[0;36mload_dotenv\u001b[0;34m(dotenv_path, stream, verbose, override, interpolate, encoding)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a .env file and then load all the variables found as environment variables.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m.env file.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dotenv_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     dotenv_path \u001b[38;5;241m=\u001b[39m \u001b[43mfind_dotenv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m dotenv \u001b[38;5;241m=\u001b[39m DotEnv(\n\u001b[1;32m    349\u001b[0m     dotenv_path\u001b[38;5;241m=\u001b[39mdotenv_path,\n\u001b[1;32m    350\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dotenv\u001b[38;5;241m.\u001b[39mset_as_environment_variables()\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen0.4/lib/python3.12/site-packages/dotenv/main.py:296\u001b[0m, in \u001b[0;36mfind_dotenv\u001b[0;34m(filename, raise_error_if_not_found, usecwd)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(main, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usecwd \u001b[38;5;129;01mor\u001b[39;00m _is_interactive() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrozen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# Should work without __file__, e.g. in REPL or IPython notebook.\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# will work for .py files\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted"
     ]
    }
   ],
   "source": [
    "# %pip install python-dotenv autogen_ext autogen_agentchat\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.tools.graphrag import GlobalSearchTool, LocalSearchTool\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "openai_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# Set up global search tool\n",
    "global_tool = GlobalSearchTool.from_settings(settings_path=\"./settings.yaml\")\n",
    "local_tool = LocalSearchTool.from_settings(settings_path=\"./settings.yaml\")\n",
    "\n",
    "# Create assistant agent with the global search tool\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"search_assistant\",\n",
    "    tools=[global_tool,local_tool],\n",
    "    model_client=openai_client,\n",
    "    system_message=(\n",
    "        \"\"\"You are a tool selector AI assistant using the GraphRAG framework. \n",
    "        Your primary task is to determine the appropriate search tool to call based on the user's query. \n",
    "        For broader, abstract questions requiring a comprehensive understanding of the dataset, call the 'global_search' function.\n",
    "        For specific questions requiring a detailed, local search, call the 'local_search' function\n",
    "        VMdata below is metadata for the VMs\n",
    "    1. VM -> Name of the virtual machine.\n",
    "    2. State -> Indicates whether the VM is ON or OFF.\n",
    "    3. Status -> Describes the VM's condition (Normal or Special).\n",
    "    4. Host -> The physical server hosting the VM.\n",
    "    5. Cluster -> The group of hosts managing the VM.\n",
    "    6. Provisioned_Space -> Total storage allocated to the VM.\n",
    "    7. Used_Space -> Storage currently used by the VM.\n",
    "    8. HostCPU -> CPU allocation on the host machine.\n",
    "    9. HostMem -> Memory allocated to the VM.\n",
    "    10. KN_SNC_DT -> Known since date of the VM record.\n",
    "    11. Decom_date -> Planned decommissioning date of the VM.\"\"\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "def chat(question, history):\n",
    "    response =  asyncio.run(\n",
    "    assistant_agent.on_messages(\n",
    "        [TextMessage(content=question, source=\"user\")], CancellationToken()\n",
    "    ))\n",
    "    print(isinstance(response.chat_message.content, dict))\n",
    "    if isinstance(response.chat_message.content, dict):\n",
    "        return response.chat_message.content.get(\"answer\")\n",
    "    return response.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer =await chat('How many VMs are there in EAPSIPVXT9753 ?',[])\n",
    "\n",
    "# Run a sample query\n",
    "query = \"What is EAPSIPVXT9753?\"\n",
    "await Console(assistant_agent.run_stream(task=query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         source  \\\n",
      "0   AppBrewery Virtual Machines   \n",
      "1   AppBrewery Virtual Machines   \n",
      "2   AppBrewery Virtual Machines   \n",
      "3   AppBrewery Virtual Machines   \n",
      "4   AppBrewery Virtual Machines   \n",
      "..                          ...   \n",
      "95  AppBrewery Virtual Machines   \n",
      "96  AppBrewery Virtual Machines   \n",
      "97  AppBrewery Virtual Machines   \n",
      "98  AppBrewery Virtual Machines   \n",
      "99  AppBrewery Virtual Machines   \n",
      "\n",
      "                                                 text timestamp  \n",
      "0   VM: app96.kwbc.net, State: OFF, Status: Normal...  20250204  \n",
      "1   VM: test55.kwbc.net, State: OFF, Status: Norma...  20250204  \n",
      "2   VM: test48.kwbc.net, State: ON, Status: Specia...  20250204  \n",
      "3   VM: db60.kwbc.net, State: OFF, Status: Normal,...  20250204  \n",
      "4   VM: dev54.kwbc.net, State: OFF, Status: Normal...  20250204  \n",
      "..                                                ...       ...  \n",
      "95  VM: backup98.kwbc.net, State: OFF, Status: Nor...  20250204  \n",
      "96  VM: infra44.kwbc.net, State: ON, Status: Norma...  20250204  \n",
      "97  VM: test66.kwbc.net, State: OFF, Status: Norma...  20250204  \n",
      "98  VM: infra59.kwbc.net, State: OFF, Status: Norm...  20250204  \n",
      "99  VM: dev75.kwbc.net, State: OFF, Status: Specia...  20250204  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Collect records in a list\n",
    "records = []\n",
    "\n",
    "for index, row in vm_data_df.iterrows():\n",
    "    record = row.to_dict()\n",
    "    record_str = ', '.join(f\"{key}: '{value}'\" for key, value in record.items())\n",
    "    source = \"AppBrewery Virtual Machines\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    records.append({\n",
    "        \"source\": source,\n",
    "        \"text\": record_str,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "\n",
    "# Create a dataframe from the records\n",
    "records_df = pd.DataFrame(records)\n",
    "print(records_df)\n",
    "records_df.to_csv('records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shivanksharma/Desktop/AI/Autogen0.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
